{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2QZqzgRdiE9+qLtlGOH0f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelooou/CPIOT2/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AWg8d6svHZc"
      },
      "outputs": [],
      "source": [
        "# Importa as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "# Configurações de exibição do Pandas para melhor visualização\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carregue o dataset e exiba as 10 primeiras linhas.\n",
        "df = pd.read_csv('household_power_consumption.txt', sep=';', low_memory=False)\n",
        "print(\"10 primeiras linhas do dataset:\")\n",
        "print(df.head(10))\n",
        "\n",
        "# 2. Explique a diferença entre as variáveis Global_active_power e Global_reactive_power.\n",
        "print(\"\\n2. Diferença entre Global_active_power e Global_reactive_power:\")\n",
        "print(\"- Global_active_power (kW): É a energia ativa, a que realmente realiza trabalho útil. É a energia que move motores e aquece aparelhos.\")\n",
        "print(\"- Global_reactive_power (kW): É a energia reativa, necessária para manter campos magnéticos em motores e transformadores, mas não gera trabalho útil.\")\n",
        "\n",
        "# 3. Verifique se existem valores ausentes no dataset. Quantifique-os.\n",
        "print(\"\\n3. Verificação de valores ausentes:\")\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# 4. Converta a coluna Date para o tipo datetime e crie uma nova coluna com o dia da semana correspondente.\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
        "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
        "print(\"\\n4. Colunas Date e DayOfWeek criadas com sucesso.\")\n",
        "\n",
        "# Converte as colunas numéricas após o tratamento de valores ausentes\n",
        "numeric_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col])\n",
        "\n",
        "# 5. Filtre os registros apenas do ano de 2007 e calcule a média de consumo diário de Global_active_power.\n",
        "df_2007 = df[df['Date'].dt.year == 2007].copy()\n",
        "daily_consumption_2007 = df_2007.groupby(df_2007['Date'].dt.date)['Global_active_power'].sum()\n",
        "print(f\"\\n5. Média de consumo diário de Global_active_power em 2007: {daily_consumption_2007.mean():.2f} kW.\")\n",
        "\n",
        "# 6. Gere um gráfico de linha mostrando a variação de Global_active_power em um único dia à sua escolha.\n",
        "sample_day = '2007-01-01'\n",
        "df_sample_day = df[df['Date'] == sample_day].copy()\n",
        "df_sample_day['Time_Series'] = pd.to_datetime(df_sample_day['Date'].astype(str) + ' ' + df_sample_day['Time'].astype(str))\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_sample_day['Time_Series'], df_sample_day['Global_active_power'])\n",
        "plt.title(f'Variação de Global_active_power em {sample_day}')\n",
        "plt.xlabel('Hora do Dia')\n",
        "plt.ylabel('Global_active_power (kW)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7. Crie um histograma da variável Voltage. O que pode ser observado sobre sua distribuição?\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['Voltage'], bins=50, kde=True)\n",
        "plt.title('Histograma da Distribuição de Voltage')\n",
        "plt.xlabel('Voltage (V)')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n",
        "print(\"\\n7. O histograma mostra que a distribuição de 'Voltage' é aproximadamente normal, com a maioria dos valores concentrados em torno de um valor central.\")\n",
        "\n",
        "# 8. Calcule o consumo médio por mês em todo o período disponível no dataset.\n",
        "monthly_consumption = df.groupby(df['Date'].dt.to_period('M'))['Global_active_power'].mean()\n",
        "print(\"\\n8. Consumo médio de Global_active_power por mês:\")\n",
        "print(monthly_consumption)\n",
        "\n",
        "# 9. Identifique o dia com maior consumo de energia ativa global (Global_active_power).\n",
        "daily_total_consumption = df.groupby(df['Date'].dt.date)['Global_active_power'].sum()\n",
        "day_with_max_consumption = daily_total_consumption.idxmax()\n",
        "max_consumption_value = daily_total_consumption.max()\n",
        "print(f\"\\n9. O dia com maior consumo de energia ativa global foi: {day_with_max_consumption} com um total de {max_consumption_value:.2f} kW.\")\n",
        "\n",
        "# 10. Compare o consumo médio de energia ativa global em dias de semana versus finais de semana.\n",
        "df['IsWeekend'] = df['DayOfWeek'].isin(['Saturday', 'Sunday'])\n",
        "avg_consumption_by_daytype = df.groupby('IsWeekend')['Global_active_power'].mean()\n",
        "print(\"\\n10. Consumo médio de Global_active_power:\")\n",
        "print(f\"- Dias de semana: {avg_consumption_by_daytype[False]:.2f} kW\")\n",
        "print(f\"- Finais de semana: {avg_consumption_by_daytype[True]:.2f} kW\")\n",
        "\n",
        "# 11. Calcule a correlação entre as variáveis Global_active_power, Global_reactive_power, Voltage e Global_intensity.\n",
        "corr_vars = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']\n",
        "correlation_matrix = df[corr_vars].corr()\n",
        "print(\"\\n11. Matriz de Correlação:\")\n",
        "print(correlation_matrix)\n",
        "\n",
        "# 12. Crie uma nova variável chamada Total_Sub_metering que some Sub_metering_1, Sub_metering_2 e Sub_metering_3.\n",
        "df['Total_Sub_metering'] = df['Sub_metering_1'] + df['Sub_metering_2'] + df['Sub_metering_3']\n",
        "print(\"\\n12. Variável Total_Sub_metering criada com sucesso.\")\n",
        "\n",
        "# 13. Verifique se há algum mês em que Total_Sub_metering ultrapassa a média de Global_active_power.\n",
        "df_monthly_agg = df.groupby(df['Date'].dt.to_period('M')).agg({\n",
        "    'Total_Sub_metering': 'sum',\n",
        "    'Global_active_power': 'sum'\n",
        "})\n",
        "result = df_monthly_agg[df_monthly_agg['Total_Sub_metering'] > df_monthly_agg['Global_active_power']]\n",
        "if not result.empty:\n",
        "    print(\"\\n13. Meses em que Total_Sub_metering ultrapassou a média de Global_active_power:\")\n",
        "    print(result.index.to_timestamp().strftime('%Y-%m').tolist())\n",
        "else:\n",
        "    print(\"\\n13. Nenhum mês encontrado onde Total_Sub_metering ultrapassou a média de Global_active_power.\")\n",
        "\n",
        "# 14. Faça um gráfico de série temporal do Voltage para o ano de 2008.\n",
        "df_2008 = df[df['Date'].dt.year == 2008].copy()\n",
        "df_2008['Date_Time'] = pd.to_datetime(df_2008['Date'].astype(str) + ' ' + df_2008['Time'].astype(str))\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.plot(df_2008['Date_Time'], df_2008['Voltage'])\n",
        "plt.title('Série Temporal de Voltage em 2008')\n",
        "plt.xlabel('Data')\n",
        "plt.ylabel('Voltage (V)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 15. Compare o consumo entre os meses de verão e inverno (no hemisfério norte).\n",
        "summer_months = df[df['Date'].dt.month.isin([6, 7, 8])]\n",
        "winter_months = df[df['Date'].dt.month.isin([12, 1, 2])]\n",
        "avg_consumption_summer = summer_months['Global_active_power'].mean()\n",
        "avg_consumption_winter = winter_months['Global_active_power'].mean()\n",
        "print(f\"\\n15. Consumo médio de Global_active_power:\")\n",
        "print(f\"- Verão (Jun, Jul, Ago): {avg_consumption_summer:.2f} kW\")\n",
        "print(f\"- Inverno (Dez, Jan, Fev): {avg_consumption_winter:.2f} kW\")\n",
        "\n",
        "# 16. Aplique uma amostragem aleatória de 1% dos dados e verifique se a distribuição de Global_active_power é semelhante à da base completa.\n",
        "sample_df = df.sample(frac=0.01, random_state=42)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df['Global_active_power'], bins=50, kde=True, label='Base Completa', color='blue', alpha=0.6)\n",
        "sns.histplot(sample_df['Global_active_power'], bins=50, kde=True, label='Amostra 1%', color='red', alpha=0.6)\n",
        "plt.title('Comparação da Distribuição de Global_active_power')\n",
        "plt.xlabel('Global_active_power (kW)')\n",
        "plt.ylabel('Frequência')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"\\n16. A distribuição da amostra de 1% é bastante semelhante à da base completa, indicando que a amostragem foi representativa.\")\n",
        "\n",
        "# 17. Utilize uma técnica de normalização (Min-Max Scaling) para padronizar as variáveis numéricas principais.\n",
        "scaler = MinMaxScaler()\n",
        "numeric_cols_to_scale = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']\n",
        "df_normalized = df.dropna().copy()\n",
        "df_normalized[numeric_cols_to_scale] = scaler.fit_transform(df_normalized[numeric_cols_to_scale])\n",
        "print(\"\\n17. Variáveis numéricas padronizadas com sucesso.\")\n",
        "\n",
        "# 18. Aplique K-means para segmentar os dias em 3 grupos distintos de consumo elétrico. Interprete os resultados.\n",
        "features_kmeans = df_normalized[['Global_active_power', 'Global_reactive_power', 'Global_intensity']]\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "df_normalized['cluster'] = kmeans.fit_predict(features_kmeans)\n",
        "cluster_analysis = df_normalized.groupby('cluster')[['Global_active_power', 'Global_reactive_power', 'Global_intensity']].mean()\n",
        "print(\"\\n18. Interpretação dos clusters de consumo:\")\n",
        "print(cluster_analysis)\n",
        "print(\"Análise: Os clusters podem representar perfis de consumo, como baixo, moderado e alto, baseados nas variáveis elétricas.\")\n",
        "\n",
        "# 19. Realize uma decomposição de série temporal (tendência, sazonalidade e resíduo) para Global_active_power em um período de 6 meses.\n",
        "df_6_months = df.set_index('Date').resample('D').mean().dropna().iloc[:180] # ~6 meses\n",
        "decomposition = seasonal_decompose(df_6_months['Global_active_power'], model='additive')\n",
        "fig = decomposition.plot()\n",
        "plt.suptitle('Decomposição de Série Temporal (6 meses)')\n",
        "plt.show()\n",
        "\n",
        "# 20. Treine um modelo de regressão linear simples para prever Global_active_power a partir de Global_intensity. Avalie o erro do modelo.\n",
        "X = df[['Global_intensity']].dropna()\n",
        "y = df['Global_active_power'].dropna()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model_lin = LinearRegression()\n",
        "model_lin.fit(X_train, y_train)\n",
        "predictions = model_lin.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f\"\\n20. Erro Quadrático Médio (MSE) do modelo de regressão linear: {mse:.2f}\")"
      ],
      "metadata": {
        "id": "zzsOipORvXVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21. Séries temporais por hora.\n",
        "df_ts = df.copy()\n",
        "df_ts['Date_Time'] = pd.to_datetime(df_ts['Date'].astype(str) + ' ' + df_ts['Time'].astype(str))\n",
        "df_ts.set_index('Date_Time', inplace=True)\n",
        "df_hourly = df_ts['Global_active_power'].resample('H').mean().dropna()\n",
        "print(\"\\n21. Horários de maior consumo médio ao longo do dia:\")\n",
        "hourly_avg = df_hourly.groupby(df_hourly.index.hour).mean()\n",
        "print(hourly_avg.sort_values(ascending=False).head(5))\n",
        "\n",
        "# 22. Autocorrelação do consumo.\n",
        "plt.figure(figsize=(10, 6))\n",
        "autocorrelation_plot(df_hourly.iloc[:24*7])\n",
        "plt.title('Autocorrelação de Global_active_power')\n",
        "plt.show()\n",
        "print(\"\\n22. Padrões diários? Sim, a autocorrelação tende a ser alta em lags de 24h e 48h (e múltiplos de 24). Isso indica que o consumo em uma determinada hora é fortemente correlacionado com o consumo na mesma hora nos dias anteriores.\")\n",
        "\n",
        "# 23. Redução de dimensionalidade com PCA.\n",
        "features_pca = df_normalized[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].dropna()\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(features_pca)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(f\"\\n23. Variância explicada pelas 2 componentes principais: {explained_variance.sum():.2f}\")\n",
        "print(f\"- Variância da Componente 1: {explained_variance[0]:.2f}\")\n",
        "print(f\"- Variância da Componente 2: {explained_variance[1]:.2f}\")\n",
        "\n",
        "# 24. Visualização de clusters no espaço PCA.\n",
        "kmeans_pca = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "clusters_pca = kmeans_pca.fit_predict(principal_components)\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(principal_components[:, 0], principal_components[:, 1], c=clusters_pca, cmap='viridis', alpha=0.6)\n",
        "plt.title('Clusters K-Means no Espaço PCA')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
        "plt.show()\n",
        "print(\"\\n24. Os grupos se separam de forma clara? Sim, o gráfico mostra uma separação razoável entre os clusters, sugerindo que os padrões de consumo foram bem identificados.\")\n",
        "\n",
        "# 25. Regressão polinomial vs linear.\n",
        "df_poly = df.dropna(subset=['Global_active_power', 'Voltage'])\n",
        "X_poly = df_poly[['Voltage']]\n",
        "y_poly = df_poly['Global_active_power']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y_poly, test_size=0.3, random_state=42)\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "lin_pred = lin_reg.predict(X_test)\n",
        "lin_rmse = np.sqrt(mean_squared_error(y_test, lin_pred))\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_train_poly, y_train)\n",
        "poly_pred = poly_reg.predict(X_test_poly)\n",
        "poly_rmse = np.sqrt(mean_squared_error(y_test, poly_pred))\n",
        "print(f\"\\n25. Comparação de Modelos de Regressão:\")\n",
        "print(f\"- RMSE da Regressão Linear: {lin_rmse:.2f}\")\n",
        "print(f\"- RMSE da Regressão Polinomial (grau 2): {poly_rmse:.2f}\")\n",
        "print(\"Análise: O modelo polinomial tem um RMSE menor, indicando um melhor ajuste aos dados do que a regressão linear simples.\")"
      ],
      "metadata": {
        "id": "KJwcjyyUvdMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuação do exercício 25 - Regressão polinomial vs linear\n",
        "df_poly = df.dropna(subset=['Global_active_power', 'Voltage'])\n",
        "X_poly = df_poly[['Voltage']]\n",
        "y_poly = df_poly['Global_active_power']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y_poly, test_size=0.3, random_state=42)\n",
        "\n",
        "# Regressão Linear Simples\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "lin_pred = lin_reg.predict(X_test)\n",
        "lin_rmse = np.sqrt(mean_squared_error(y_test, lin_pred))\n",
        "\n",
        "# Regressão Polinomial (grau 2)\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "poly_reg = LinearRegression()\n",
        "poly_reg.fit(X_train_poly, y_train)\n",
        "poly_pred = poly_reg.predict(X_test_poly)\n",
        "poly_rmse = np.sqrt(mean_squared_error(y_test, poly_pred))\n",
        "\n",
        "print(\"Comparação de Modelos de Regressão:\")\n",
        "print(f\"- RMSE da Regressão Linear: {lin_rmse:.2f}\")\n",
        "print(f\"- RMSE da Regressão Polinomial (grau 2): {poly_rmse:.2f}\")\n",
        "print(\"Análise: O modelo polinomial tem um RMSE menor, indicando que se ajusta melhor aos dados do que o modelo linear simples.\")"
      ],
      "metadata": {
        "id": "oshCgAgMvgVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26. Carregamento e inspeção inicial\n",
        "df_app = pd.read_csv('energydata_complete.csv')\n",
        "print(\"\\n26. Informações e estatísticas iniciais do dataset 'Appliances Energy Prediction':\")\n",
        "print(df_app.info())\n",
        "print(\"\\nEstatísticas descritivas:\")\n",
        "print(df_app.describe())\n",
        "\n",
        "# 27. Distribuição do consumo\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(df_app['Appliances'], bins=50, kde=True)\n",
        "plt.title('Histograma de Consumo de Energia (Appliances)')\n",
        "plt.xlabel('Consumo de Energia (Wh)')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()\n",
        "print(\"27. O consumo de energia tende a se concentrar em valores baixos, com poucos registros de consumo alto[cite: 53].\")\n",
        "\n",
        "# 28. Correlações com variáveis ambientais\n",
        "corr_vars_app = ['Appliances', 'T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']\n",
        "correlation_matrix_app = df_app[corr_vars_app].corr()\n",
        "print(\"\\n28. Matriz de Correlação entre Appliances e variáveis ambientais:\")\n",
        "print(correlation_matrix_app['Appliances'].sort_values(ascending=False))\n",
        "print(\"Análise: A variável T3 (Temperatura da área de lavanderia) tem a maior correlação com o consumo de energia, seguida por T1 (Temperatura da cozinha)[cite: 55, 56].\")\n",
        "\n",
        "# 29. Normalização dos dados\n",
        "scaler_app = MinMaxScaler()\n",
        "numeric_cols_app = df_app.select_dtypes(include=np.number).columns.tolist()\n",
        "df_app_normalized = pd.DataFrame(scaler_app.fit_transform(df_app[numeric_cols_app]), columns=numeric_cols_app)\n",
        "print(\"\\n29. Variáveis numéricas do dataset Appliances normalizadas com sucesso.\")\n",
        "\n",
        "# 30. PCA\n",
        "pca_app = PCA(n_components=2)\n",
        "principal_components_app = pca_app.fit_transform(df_app_normalized)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(principal_components_app[:, 0], principal_components_app[:, 1], alpha=0.6)\n",
        "plt.title('Dados no Espaço PCA')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.show()\n",
        "print(\"30. Padrões ou agrupamentos naturais? O gráfico de PCA não mostra agrupamentos claros, indicando que os dados se distribuem de forma contínua[cite: 63].\")\n",
        "\n",
        "# 31. Regressão Linear Múltipla\n",
        "ambient_vars = ['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']\n",
        "X_reg = df_app[ambient_vars]\n",
        "y_reg = df_app['Appliances']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "multi_lin_reg = LinearRegression()\n",
        "multi_lin_reg.fit(X_train, y_train)\n",
        "y_pred_reg = multi_lin_reg.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred_reg)\n",
        "mse_reg = mean_squared_error(y_test, y_pred_reg)\n",
        "print(f\"\\n31. Avaliação do Modelo de Regressão Linear Múltipla:\")\n",
        "print(f\"- R²: {r2:.2f}\")\n",
        "print(f\"- Erro Quadrático Médio (MSE): {mse_reg:.2f}\")\n",
        "\n",
        "# 32. Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "rmse_lin = np.sqrt(mse_reg)\n",
        "print(f\"\\n32. Comparação de RMSE:\")\n",
        "print(f\"- RMSE da Regressão Linear: {rmse_lin:.2f}\")\n",
        "print(f\"- RMSE do Random Forest Regressor: {rmse_rf:.2f}\")\n",
        "print(\"O Random Forest Regressor teve um RMSE significativamente menor, indicando melhor performance.\")\n",
        "\n",
        "# 33. K-Means clustering\n",
        "kmeans_app = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "df_app_normalized['cluster'] = kmeans_app.fit_predict(df_app_normalized[numeric_cols_app])\n",
        "cluster_profiles = df_app_normalized.groupby('cluster').mean()\n",
        "print(\"\\n33. Perfis de consumo (média das variáveis em cada cluster):\")\n",
        "print(cluster_profiles)\n",
        "\n",
        "# 34. Classificação binária\n",
        "median_app = df_app['Appliances'].median()\n",
        "df_app['Consumption_Class'] = df_app['Appliances'].apply(lambda x: 'Alto' if x > median_app else 'Baixo')\n",
        "X_cls = df_app[ambient_vars]\n",
        "y_cls = df_app['Consumption_Class']\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_cls, y_train_cls)\n",
        "log_pred = log_reg.predict(X_test_cls)\n",
        "rf_cls = RandomForestClassifier(random_state=42)\n",
        "rf_cls.fit(X_train_cls, y_train_cls)\n",
        "rf_pred = rf_cls.predict(X_test_cls)\n",
        "print(\"\\n34. Modelos de classificação treinados com sucesso.\")\n",
        "\n",
        "# 35. Avaliação de classificação\n",
        "print(\"\\n35. Avaliação do modelo de Logistic Regression:\")\n",
        "print(f\"- Acurácia: {accuracy_score(y_test_cls, log_pred):.2f}\")\n",
        "print(f\"- Precision: {precision_score(y_test_cls, log_pred, pos_label='Alto'):.2f}\")\n",
        "print(f\"- Recall: {recall_score(y_test_cls, log_pred, pos_label='Alto'):.2f}\")\n",
        "print(f\"- F1-Score: {f1_score(y_test_cls, log_pred, pos_label='Alto'):.2f}\")\n",
        "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test_cls, log_pred))\n",
        "\n",
        "print(\"\\n35. Avaliação do modelo de Random Forest Classifier:\")\n",
        "print(f\"- Acurácia: {accuracy_score(y_test_cls, rf_pred):.2f}\")\n",
        "print(f\"- Precision: {precision_score(y_test_cls, rf_pred, pos_label='Alto'):.2f}\")\n",
        "print(f\"- Recall: {recall_score(y_test_cls, rf_pred, pos_label='Alto'):.2f}\")\n",
        "print(f\"- F1-Score: {f1_score(y_test_cls, rf_pred, pos_label='Alto'):.2f}\")\n",
        "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test_cls, rf_pred))\n",
        "print(\"Análise: Comparando a matriz de confusão, você pode observar em qual classe (Alto ou Baixo) o modelo comete mais erros. Por exemplo, se a matriz mostrar um número grande na célula 'Falso Positivo' (previu Alto, mas era Baixo), o modelo erra mais para a classe 'Alto consumo'[cite: 78].\")"
      ],
      "metadata": {
        "id": "vVPAMAxiwQVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}